
<!--- Hugo front matter used to generate the website version of this page:
linkTitle: Generative AI evaluation events
--->

# Semantic Conventions for GenAI evaluation events

**Status**: [Experimental][DocumentStatus]

Each evaluation event defines a common way to report an evaluation score and the context for this specific evaluation method.

## User feedback evaluation

The user feedback evaluation event SHOULD be captured if and only if user provided a reaction to GenAI model response.
It SHOULD, when possible, be parented to the GenAI span describing such response.

<!-- semconv event.gen_ai.evaluation.user_feedback -->
<!-- NOTE: THIS TEXT IS AUTOGENERATED. DO NOT EDIT BY HAND. -->
<!-- see templates/registry/markdown/snippet.md.j2 -->
<!-- prettier-ignore-start -->
<!-- markdownlint-capture -->
<!-- markdownlint-disable -->

**Status:** ![Development](https://img.shields.io/badge/-development-blue)

The event name MUST be `gen_ai.evaluation.user_feedback`.

This event describes the evaluation of GenAI response based on the user feedback.

| Attribute  | Type | Description  | Examples  | [Requirement Level](https://opentelemetry.io/docs/specs/semconv/general/attribute-requirement-level/) | Stability |
|---|---|---|---|---|---|
| [`enduser.id`](/docs/attributes-registry/enduser.md) | string | Unique identifier of an end user in the system. It maybe a username, email address, or other identifier. [1] | `username` | `Recommended` if available | ![Development](https://img.shields.io/badge/-development-blue) |
| [`enduser.pseudo.id`](/docs/attributes-registry/enduser.md) | string | Pseudonymous identifier of an end user. This identifier should be a random value that is not directly linked or associated with the end user's actual identity. [2] | `QdH5CAWJgqVT4rOr0qtumf` | `Recommended` if available | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.evaluation.score`](/docs/attributes-registry/gen-ai.md) | double | Quantified score calculated based on the user reaction in [-1.0, 1.0] range with 0 representing a neutral reaction. | `0.42` | `Recommended` | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.message.id`](/docs/attributes-registry/gen-ai.md) | string | Identifies message sent to or received from Generative AI model or agent. [3] | `msg_sLMd7grQfjFXgu5ZeHCXmBr7`; `chatcmpl-123` | `Recommended` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.response.id`](/docs/attributes-registry/gen-ai.md) | string | The unique identifier for the completion. | `chatcmpl-123` | `Recommended` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.thread.id`](/docs/attributes-registry/gen-ai.md) | string | The unique identifier of the thread. | `thread_ggguJ0iZXRPjUnCy9vT9Fdvs` | `Recommended` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`session.id`](/docs/attributes-registry/session.md) | string | A unique id to identify a session. | `00112233-4455-6677-8899-aabbccddeeff` | `Recommended` if available | ![Development](https://img.shields.io/badge/-development-blue) |

**[1] `enduser.id`:** Unique identifier of an end user in the system.

> [!Warning]
> This field contains sensitive (PII) information.

**[2] `enduser.pseudo.id`:** Pseudonymous identifier of an end user.

> [!Warning]
> This field contains sensitive (linkable PII) information.

**[3] `gen_ai.message.id`:** For inference operations such as `chat` or `text_completion`, it SHOULD be the completion identifier returned by the GenAI system and may not be unique if multiple choices are returned.
If message history is managed by the application, agent, or framework, it SHOULD match the identifier used by the message history management system.

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->
<!-- END AUTOGENERATED TEXT -->
<!-- endsemconv -->

The user feedback event body has the following structure:

| Body Field | Type | Description | Examples | Requirement Level |
|---|---|---|---|---|
| `comment` | string | Additional details about the user feedback | `"I did not like it"` | `Opt-in` |

> [NOTE!]
>
> Since logs and events API is not stable in at least some languages including Python,
> Azure AI instrumentations and evaluators MAY report [GenAI events](./gen-ai-events.md) on
> span events instead.
>
> When span events are used, the event body MUST be reported as a JSON string on the
> `gen_ai.event.content` attribute.

## Generic evaluation result

<!-- semconv event.gen_ai.evaluation.result -->
<!-- NOTE: THIS TEXT IS AUTOGENERATED. DO NOT EDIT BY HAND. -->
<!-- see templates/registry/markdown/snippet.md.j2 -->
<!-- prettier-ignore-start -->
<!-- markdownlint-capture -->
<!-- markdownlint-disable -->

**Status:** ![Development](https://img.shields.io/badge/-development-blue)

The event name MUST be `gen_ai.evaluation.result`.

This event describes a generic GenAI response evaluation result.

| Attribute  | Type | Description  | Examples  | [Requirement Level](https://opentelemetry.io/docs/specs/semconv/general/attribute-requirement-level/) | Stability |
|---|---|---|---|---|---|
| [`gen_ai.evaluator.name`](/docs/attributes-registry/gen-ai.md) | string | The qualified name of the evaluator used to evaluate the GenAI response. | `azureml://registries/azureml/models/Relevance-Evaluator`; `azure.ai.evaluation.ToolCallAccuracyEvaluator` | `Required` | ![Development](https://img.shields.io/badge/-development-blue) |
| [`error.type`](/docs/attributes-registry/error.md) | string | Describes a class of error the operation ended with. [1] | `timeout`; `java.net.UnknownHostException`; `server_certificate_invalid`; `500` | `Conditionally Required` if and only if evaluation failed | ![Stable](https://img.shields.io/badge/-stable-lightgreen) |
| [`gen_ai.evaluation.score`](/docs/attributes-registry/gen-ai.md) | double | The score calculated by the evaluator for the GenAI response. | `0.42` | `Conditionally Required` if evaluation completed successfully | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.response.id`](/docs/attributes-registry/gen-ai.md) | string | The unique identifier for the completion. | `chatcmpl-123` | `Conditionally Required` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.thread.id`](/docs/attributes-registry/gen-ai.md) | string | The unique identifier of the thread. | `thread_ggguJ0iZXRPjUnCy9vT9Fdvs` | `Conditionally Required` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.thread.run.id`](/docs/attributes-registry/gen-ai.md) | string | The unique identifier of the thread run. | `run_ep8IxBKdM06Mv338KNyo6EKP` | `Conditionally Required` if applicable | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.evaluation.input.metadata`](/docs/attributes-registry/gen-ai.md) | string | Metadata associated with the evaluation input. [2] | `{\"requestId\": \"fab3ee5d-a3c6-4c47-b3de-901bf02fa045\"}` | `Recommended` | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.evaluation.output.metadata`](/docs/attributes-registry/gen-ai.md) | string | Metadata associated with the evaluation result. [3] | `{\"Perplexity\": 1.335}` | `Recommended` | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.evaluation.reasoning`](/docs/attributes-registry/gen-ai.md) | string | A free-form reasoning for the assigned score provided by the evaluator. | `The response is factually accurate but lacks sufficient detail to fully address the question.` | `Recommended` | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.usage.input_tokens`](/docs/attributes-registry/gen-ai.md) | int | The total number of input tokens used by the model during the evaluation. | `100` | `Recommended` if evaluation was performed by the model | ![Development](https://img.shields.io/badge/-development-blue) |
| [`gen_ai.usage.output_tokens`](/docs/attributes-registry/gen-ai.md) | int | The total number of output tokens generated by the model during the evaluation. | `180` | `Recommended` if evaluation was performed by the model | ![Development](https://img.shields.io/badge/-development-blue) |

**[1] `error.type`:** The `error.type` SHOULD be predictable, and SHOULD have low cardinality.

When `error.type` is set to a type (e.g., an exception type), its
canonical class name identifying the type within the artifact SHOULD be used.

Instrumentations SHOULD document the list of errors they report.

The cardinality of `error.type` within one instrumentation library SHOULD be low.
Telemetry consumers that aggregate data from multiple instrumentation libraries and applications
should be prepared for `error.type` to have high cardinality at query time when no
additional filters are applied.

If the operation has completed successfully, instrumentations SHOULD NOT set `error.type`.

If a specific domain defines its own set of error identifiers (such as HTTP or gRPC status codes),
it's RECOMMENDED to:

- Use a domain-specific attribute
- Set `error.type` to capture all errors, regardless of whether they are defined within the domain-specific set or not.

**[2] `gen_ai.evaluation.input.metadata`:** The structure is specific to the evaluator.
If the metadata is structured, it is RECOMMENDED to provide it in a structured form using language-specific API. It can also be captured as a JSON string when structured API is not available.
If metadata properties contain any sensitive information such as prompts or completions, corresponding properties MUST NOT be recorded by default.
Instrumentations MAY provide a way to override this behavior and record sensitive information in the metadata if user explicitly allows it.

**[3] `gen_ai.evaluation.output.metadata`:** The structure is specific to the evaluator.
If the metadata is structured, it is RECOMMENDED to provide it in a structured form using language-specific API. It can also be captured as a JSON string when structured API is not available.
If metadata properties contain any sensitive information such as prompts or completions, corresponding properties MUST NOT be recorded by default.
Instrumentations MAY provide a way to override this behavior and record sensitive information in the metadata if user explicitly allows it.

---

`error.type` has the following list of well-known values. If one of them applies, then the respective value MUST be used; otherwise, a custom value MAY be used.

| Value  | Description | Stability |
|---|---|---|
| `_OTHER` | A fallback error value to be used when the instrumentation doesn't define a custom value. | ![Stable](https://img.shields.io/badge/-stable-lightgreen) |

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->
<!-- END AUTOGENERATED TEXT -->
<!-- endsemconv -->

[DocumentStatus]: https://opentelemetry.io/docs/specs/otel/document-status
